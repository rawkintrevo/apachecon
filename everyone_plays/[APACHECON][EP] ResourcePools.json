{"paragraphs":[{"config":{"colWidth":8,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461696251621_-1067995746","id":"20160426-134411_1559882364","dateCreated":"Apr 26, 2016 1:44:11 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5954","text":"%md\n\n# Everyone Plays: Collaborative Data Science with Apache Zeppelin\n*trevor grant, aka @rawkintrevo*","dateUpdated":"Apr 26, 2016 1:44:38 PM","dateFinished":"Apr 26, 2016 1:44:36 PM","dateStarted":"Apr 26, 2016 1:44:36 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Everyone Plays: Collaborative Data Science with Apache Zeppelin</h1>\n<p><em>trevor grant, aka @rawkintrevo</em></p>\n"}},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"title":true,"editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461696221037_-511310061","id":"20160426-134341_273697276","dateCreated":"Apr 26, 2016 1:43:41 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5820","text":"%md\n\n__*trevor grant*__\n*r&d data scientist at market6*\n*trevor.d.grant@gmail.com*\n*@rawkintrevo*\n*[http://github.com/rawkintrevo](http://github.com/rawkintrevo)*","dateUpdated":"Apr 26, 2016 1:44:59 PM","dateFinished":"Apr 26, 2016 1:44:57 PM","dateStarted":"Apr 26, 2016 1:44:57 PM","title":"about the author","result":{"code":"SUCCESS","type":"HTML","msg":"<p><strong><em>trevor grant</em></strong>\n<br  /><em>r&amp;d data scientist at market6</em>\n<br  /><em>trevor.d.grant@gmail.com</em>\n<br  /><em>@rawkintrevo</em>\n<br  /><em><a href=\"http://github.com/rawkintrevo\">http://github.com/rawkintrevo</a></em></p>\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461693954550_1216192840","id":"20160426-130554_1820744158","dateCreated":"Apr 26, 2016 1:05:54 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4495","text":"%md \n\n## Zeppelin `ResourcePool` for sharing objects between interpreters\n\nThe *Spark Family* of interpreters (`%spark`, `%sql`, `%pyspark`, `%r`) have access to the `ResourcePool` via the `ZeppelinContext` e.g. `z.put(varName)`/`z.get(varName)`. \n\nOther interpreters must be more explicit in accessing.","dateUpdated":"Apr 26, 2016 1:43:38 PM","dateFinished":"Apr 26, 2016 1:12:59 PM","dateStarted":"Apr 26, 2016 1:12:59 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<h2>Zeppelin <code>ResourcePool</code> for sharing objects between interpreters</h2>\n<p>The <em>Spark Family</em> of interpreters (<code>%spark</code>, <code>%sql</code>, <code>%pyspark</code>, <code>%r</code>) have access to the <code>ResourcePool</code> via the <code>ZeppelinContext</code> e.g. <code>z.put(varName)</code>/<code>z.get(varName)</code>.  Other interpreters must be more explicit in accessing.</p>\n"},"focus":true},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461693986421_-422836950","id":"20160426-130626_1014369242","dateCreated":"Apr 26, 2016 1:06:26 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4638","text":"%flink\n// for flink we have to declare declare the resource pool\nimport org.apache.zeppelin.interpreter.InterpreterContext\n\nval resourcePool = InterpreterContext.get().getResourcePool()","dateUpdated":"Apr 26, 2016 1:09:04 PM","dateFinished":"Apr 26, 2016 1:09:05 PM","dateStarted":"Apr 26, 2016 1:09:04 PM","title":"Flink explicitly accesses the ResourcePool","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.zeppelin.interpreter.InterpreterContext\nresourcePool: org.apache.zeppelin.resource.ResourcePool = org.apache.zeppelin.resource.DistributedResourcePool@21d07d88\n"}},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461694153462_-1243628948","id":"20160426-130913_1268061074","dateCreated":"Apr 26, 2016 1:09:13 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4731","text":"%flink\n// Put a variable in the resource pool\nval foo = \"bar\"\nresourcePool.put(\"foo\", \"bar\")","dateUpdated":"Apr 26, 2016 1:10:47 PM","dateFinished":"Apr 26, 2016 1:10:47 PM","dateStarted":"Apr 26, 2016 1:10:47 PM","title":"Flink puts something in the ResourcePool","result":{"code":"SUCCESS","type":"TEXT","msg":"foo: String = bar\n"}},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"title":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461693979569_-210086133","id":"20160426-130619_1599299213","dateCreated":"Apr 26, 2016 1:06:19 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4563","dateUpdated":"Apr 26, 2016 1:12:25 PM","dateFinished":"Apr 26, 2016 1:11:58 PM","dateStarted":"Apr 26, 2016 1:11:57 PM","title":"Spark accesses via Zeppelin Context","result":{"code":"SUCCESS","type":"TEXT","msg":"foo is: bar\n"},"text":"%spark\n\n// Spark has some built in wrapper. Let's get \"foo\" from the resource pool \nprintln(\"foo is: \"+ z.get(\"foo\"))"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461694317984_1174162144","id":"20160426-131157_239791009","dateCreated":"Apr 26, 2016 1:11:57 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4806","dateUpdated":"Apr 26, 2016 1:14:49 PM","dateFinished":"Apr 26, 2016 1:14:46 PM","dateStarted":"Apr 26, 2016 1:14:46 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Any serializable object (not just strings) can be placed in the resource pool.</p>\n"},"text":"%md\nAny serializable object (not just strings) can be placed in the resource pool. "},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"title":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461694486049_1572624087","id":"20160426-131446_205490522","dateCreated":"Apr 26, 2016 1:14:46 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4883","dateUpdated":"Apr 26, 2016 1:15:47 PM","dateFinished":"Apr 26, 2016 1:15:47 PM","dateStarted":"Apr 26, 2016 1:15:47 PM","title":"Spark puts a List in the ResourcePool","result":{"code":"SUCCESS","type":"TEXT","msg":""},"text":"%spark\n\nz.put(\"foo2\", List(1,2,3))"},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"title":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461694518461_1132284167","id":"20160426-131518_2014344027","dateCreated":"Apr 26, 2016 1:15:18 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4956","dateUpdated":"Apr 26, 2016 1:21:17 PM","dateFinished":"Apr 26, 2016 1:20:46 PM","dateStarted":"Apr 26, 2016 1:20:45 PM","title":"Get variable from ResourcePool, put updated back in pool","result":{"code":"SUCCESS","type":"TEXT","msg":"foo2: List[Int] = List(1, 2, 3)\nfoo2 is: List(1, 2, 3)\nfoo3: List[Int] = List(2, 3, 4)\n"},"text":"%flink\n\nval foo2 = resourcePool.get(\"foo2\").get().asInstanceOf[List[Int]];\nprintln(\"foo2 is: \" + foo2)\nval foo3 = foo2.map(_ + 1)\nresourcePool.put(\"foo3\", foo3)\n"},{"config":{"colWidth":4,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"title":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461694547170_-191206077","id":"20160426-131547_1561836102","dateCreated":"Apr 26, 2016 1:15:47 PM","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5024","dateUpdated":"Apr 26, 2016 1:22:04 PM","dateFinished":"Apr 26, 2016 1:22:14 PM","dateStarted":"Apr 26, 2016 1:22:04 PM","title":"pySpark too!","result":{"code":"ERROR","type":"TEXT","msg":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-2531280711477974383.py\", line 20, in <module>\n    from py4j.java_gateway import java_import, JavaGateway, GatewayClient\nImportError: No module named py4j.java_gateway\npyspark is not responding Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-2531280711477974383.py\", line 20, in <module>\n    from py4j.java_gateway import java_import, JavaGateway, GatewayClient\nImportError: No module named py4j.java_gateway\n"},"text":"%pyspark\n\nprint \"foo: \", z.get(\"foo\"), \",foo2: \", z.get(\"foo2\"), \"foo3: \", z.get(\"foo3\")"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461694924316_-1576148876","id":"20160426-132204_2101065672","dateCreated":"Apr 26, 2016 1:22:04 PM","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5198"}],"name":"[APACHECON][EP] ResourcePools","id":"2BJUG641M","angularObjects":{"2B9FGGAMR":[],"2BAUGSG18":[],"2B7FY26FF":[],"2BA9PQW6K":[],"2BANREB9T":[],"2B91YJ1JR":[],"2B89JN8NB":[],"2BAZ6AN3R":[],"2B95VQPWE":[],"2B9NH1VM4":[],"2B7JPXM9Z":[],"2BAV7BWDX":[],"2B88H2DWF":[]},"config":{"looknfeel":"default"},"info":{}}